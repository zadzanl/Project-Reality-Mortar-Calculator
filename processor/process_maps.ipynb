{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b143385c",
   "metadata": {},
   "source": [
    "## Cell 1: Imports and Environment Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Map processing notebook - converts PR:BF2 heightmaps to JSON format.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import struct\n",
    "import json\n",
    "import subprocess\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "# NumPy for array operations\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"✓ NumPy loaded\")\n",
    "except ImportError:\n",
    "    print(\"Installing NumPy...\")\n",
    "    %pip install -q numpy\n",
    "    import numpy as np\n",
    "    print(\"✓ NumPy installed and loaded\")\n",
    "\n",
    "# Detect environment\n",
    "try:\n",
    "    IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Verify repository structure\n",
    "repo_root = Path.cwd()\n",
    "if not (repo_root / 'raw_map_data').exists():\n",
    "    # Try parent directory (in case running from processor/)\n",
    "    if (repo_root.parent / 'raw_map_data').exists():\n",
    "        repo_root = repo_root.parent\n",
    "        os.chdir(repo_root)\n",
    "    else:\n",
    "        print(\"⚠ WARNING: raw_map_data/ directory not found!\")\n",
    "        print(\"   Make sure you cloned the repository and are in the correct directory.\")\n",
    "        print(f\"   Current directory: {repo_root}\")\n",
    "\n",
    "print(f\"Repository root: {repo_root}\")\n",
    "print(f\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ce173",
   "metadata": {},
   "source": [
    "## Cell 2: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b750af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_terrain_con(content: str) -> Optional[float]:\n",
    "    \"\"\"Parse terrain.con file to extract height scale.\n",
    "    \n",
    "    Args:\n",
    "        content: Content of terrain.con file\n",
    "        \n",
    "    Returns:\n",
    "        Height scale in meters, or None if not found\n",
    "    \"\"\"\n",
    "    # Look for: HeightmapCluster.setHeightScale X\n",
    "    match = re.search(r'HeightmapCluster\\.setHeightScale\\s+(\\d+\\.?\\d*)', content, re.IGNORECASE)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_init_con(content: str) -> Optional[int]:\n",
    "    \"\"\"Parse init.con file to extract map size.\n",
    "    \n",
    "    Args:\n",
    "        content: Content of init.con file\n",
    "        \n",
    "    Returns:\n",
    "        Map size in meters, or None if not found\n",
    "    \"\"\"\n",
    "    # Look for: heightmapCluster.create X Y Z\n",
    "    match = re.search(r'heightmapCluster\\.create\\s+(\\d+)\\s+(\\d+)', content, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))  # First value is map size\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_heightmap_raw(server_zip_path: Path) -> Optional[np.ndarray]:\n",
    "    \"\"\"Extract and parse HeightmapPrimary.raw from server.zip.\n",
    "    \n",
    "    Args:\n",
    "        server_zip_path: Path to server.zip file\n",
    "        \n",
    "    Returns:\n",
    "        2D NumPy array of uint16 values, or None if extraction failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(server_zip_path, 'r') as zf:\n",
    "            # Find heightmapprimary.raw (case-insensitive)\n",
    "            heightmap_file = None\n",
    "            for name in zf.namelist():\n",
    "                if 'heightmapprimary.raw' in name.lower():\n",
    "                    heightmap_file = name\n",
    "                    break\n",
    "            \n",
    "            if not heightmap_file:\n",
    "                return None\n",
    "            \n",
    "            # Read raw bytes\n",
    "            raw_data = zf.read(heightmap_file)\n",
    "            \n",
    "            # Determine resolution from file size\n",
    "            # 16-bit = 2 bytes per pixel\n",
    "            num_pixels = len(raw_data) // 2\n",
    "            resolution = int(np.sqrt(num_pixels))\n",
    "            \n",
    "            # Parse as 16-bit unsigned integers (little-endian)\n",
    "            heightmap_1d = np.frombuffer(raw_data, dtype='<u2')  # '<u2' = little-endian uint16\n",
    "            \n",
    "            # Reshape to 2D array\n",
    "            heightmap_2d = heightmap_1d.reshape((resolution, resolution))\n",
    "            \n",
    "            return heightmap_2d\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Error extracting heightmap: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_config_files(server_zip_path: Path) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"Extract init.con and terrain.con from server.zip.\n",
    "    \n",
    "    Args:\n",
    "        server_zip_path: Path to server.zip file\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (init_con_content, terrain_con_content)\n",
    "    \"\"\"\n",
    "    init_con = None\n",
    "    terrain_con = None\n",
    "    \n",
    "    try:\n",
    "        with zipfile.ZipFile(server_zip_path, 'r') as zf:\n",
    "            for name in zf.namelist():\n",
    "                if name.endswith('init.con'):\n",
    "                    init_con = zf.read(name).decode('utf-8', errors='ignore')\n",
    "                elif name.endswith('terrain.con'):\n",
    "                    terrain_con = zf.read(name).decode('utf-8', errors='ignore')\n",
    "    except Exception as e:\n",
    "        print(f\"  Error extracting config files: {e}\")\n",
    "    \n",
    "    return init_con, terrain_con\n",
    "\n",
    "\n",
    "def convert_heightmap_to_json(heightmap: np.ndarray, output_path: Path) -> bool:\n",
    "    \"\"\"Convert heightmap array to JSON format.\n",
    "    \n",
    "    Args:\n",
    "        heightmap: 2D NumPy array of uint16 values\n",
    "        output_path: Path to output JSON file\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resolution = heightmap.shape[0]\n",
    "        \n",
    "        # Flatten to 1D array (row-major order)\n",
    "        heightmap_flat = heightmap.flatten().tolist()\n",
    "        \n",
    "        # Create JSON structure\n",
    "        data = {\n",
    "            'resolution': resolution,\n",
    "            'width': resolution,\n",
    "            'height': resolution,\n",
    "            'format': 'uint16',\n",
    "            'data': heightmap_flat,\n",
    "            'compression': 'none'\n",
    "        }\n",
    "        \n",
    "        # Write JSON\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, separators=(',', ':'))  # Compact format\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error converting to JSON: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def generate_metadata(map_name: str, heightmap: np.ndarray, \n",
    "                     map_size: Optional[int], height_scale: Optional[float],\n",
    "                     output_path: Path) -> bool:\n",
    "    \"\"\"Generate metadata.json file.\n",
    "    \n",
    "    Args:\n",
    "        map_name: Name of the map\n",
    "        heightmap: 2D NumPy array\n",
    "        map_size: Map size in meters (from init.con)\n",
    "        height_scale: Height scale in meters (from terrain.con)\n",
    "        output_path: Path to output JSON file\n",
    "        \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resolution = heightmap.shape[0]\n",
    "        \n",
    "        # Use defaults if not found\n",
    "        if map_size is None:\n",
    "            # Guess from resolution\n",
    "            map_size = 2048 if resolution == 1025 else 4096\n",
    "        \n",
    "        if height_scale is None:\n",
    "            height_scale = 300  # Default\n",
    "        \n",
    "        # Calculate grid scale\n",
    "        # 13x13 grid system\n",
    "        grid_scale = map_size / 13\n",
    "        \n",
    "        metadata = {\n",
    "            'map_name': map_name,\n",
    "            'map_size': map_size,\n",
    "            'height_scale': height_scale,\n",
    "            'grid_scale': grid_scale,\n",
    "            'heightmap_resolution': resolution,\n",
    "            'processed_at': datetime.utcnow().isoformat() + 'Z',\n",
    "            'format_version': '1.0'\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error generating metadata: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "print(\"✓ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a2cf61",
   "metadata": {},
   "source": [
    "## Cell 3: Git Configuration\n",
    "\n",
    "**Important:** You'll need to provide your Git credentials for automatic commit and push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8a285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Git Configuration\\n\" + \"=\"*70)\n",
    "print(\"Please provide your Git credentials for automatic commit and push.\\n\")\n",
    "\n",
    "# Get user input\n",
    "GIT_USER_NAME = input(\"Git user name (e.g., 'John Doe'): \").strip()\n",
    "GIT_USER_EMAIL = input(\"Git user email (e.g., 'john@example.com'): \").strip()\n",
    "GITHUB_TOKEN = input(\"GitHub Personal Access Token: \").strip()\n",
    "\n",
    "# Validate inputs\n",
    "if not all([GIT_USER_NAME, GIT_USER_EMAIL, GITHUB_TOKEN]):\n",
    "    print(\"\\n⚠ ERROR: All fields are required!\")\n",
    "    print(\"Please re-run this cell and provide all credentials.\")\n",
    "else:\n",
    "    # Configure git\n",
    "    try:\n",
    "        subprocess.run(['git', 'config', 'user.name', GIT_USER_NAME], check=True, capture_output=True)\n",
    "        subprocess.run(['git', 'config', 'user.email', GIT_USER_EMAIL], check=True, capture_output=True)\n",
    "        \n",
    "        print(\"\\n✓ Git configured successfully\")\n",
    "        print(f\"  User: {GIT_USER_NAME} <{GIT_USER_EMAIL}>\")\n",
    "        print(f\"  Token: {'*' * len(GITHUB_TOKEN)}\")\n",
    "        \n",
    "        # Get repository info\n",
    "        result = subprocess.run(\n",
    "            ['git', 'config', '--get', 'remote.origin.url'],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        repo_url = result.stdout.strip()\n",
    "        print(f\"  Repository: {repo_url}\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n⚠ ERROR: Git configuration failed\")\n",
    "        print(f\"  {e}\")\n",
    "        print(\"  Make sure you're in a git repository and git is installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d0f1c",
   "metadata": {},
   "source": [
    "## Cell 4: Load Manifest and Discover Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb005c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load manifest\n",
    "raw_data_dir = repo_root / 'raw_map_data'\n",
    "manifest_path = raw_data_dir / 'manifest.json'\n",
    "\n",
    "if not manifest_path.exists():\n",
    "    print(\"⚠ WARNING: manifest.json not found!\")\n",
    "    print(f\"  Expected at: {manifest_path}\")\n",
    "    print(\"  Run processor/collect_maps.py first to collect map data.\")\n",
    "    manifest_data = {'maps': []}\n",
    "else:\n",
    "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
    "        manifest_data = json.load(f)\n",
    "    \n",
    "    print(f\"✓ Loaded manifest\")\n",
    "    print(f\"  Total maps: {manifest_data.get('total_maps', 0)}\")\n",
    "    print(f\"  Total size: {manifest_data.get('total_size_mb', 0):.1f} MB\")\n",
    "    print(f\"  Collection date: {manifest_data.get('collection_date', 'unknown')}\")\n",
    "\n",
    "# Discover server.zip files\n",
    "server_zip_files = []\n",
    "for map_info in manifest_data.get('maps', []):\n",
    "    map_name = map_info['name']\n",
    "    zip_path = raw_data_dir / map_name / 'server.zip'\n",
    "    \n",
    "    if zip_path.exists():\n",
    "        server_zip_files.append((map_name, zip_path))\n",
    "    else:\n",
    "        print(f\"⚠ WARNING: Missing {zip_path}\")\n",
    "\n",
    "print(f\"\\n✓ Found {len(server_zip_files)} server.zip files to process\")\n",
    "\n",
    "if len(server_zip_files) == 0:\n",
    "    print(\"\\n⚠ No files to process!\")\n",
    "    print(\"  Make sure raw_map_data/ directory contains map folders with server.zip files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634e7af",
   "metadata": {},
   "source": [
    "## Cell 5: Processing Loop\n",
    "\n",
    "This cell processes all maps. Progress will be displayed as processing proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "processed_dir = repo_root / 'processed_maps'\n",
    "processed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Processing statistics\n",
    "stats = {\n",
    "    'total': len(server_zip_files),\n",
    "    'processed': 0,\n",
    "    'errors': 0,\n",
    "    'error_maps': []\n",
    "}\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Processing {stats['total']} maps...\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i, (map_name, zip_path) in enumerate(server_zip_files, 1):\n",
    "    print(f\"[{i}/{stats['total']}] {map_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Create output directory for this map\n",
    "        map_output_dir = processed_dir / map_name\n",
    "        map_output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Extract heightmap\n",
    "        print(f\"  Extracting heightmap...\")\n",
    "        heightmap = extract_heightmap_raw(zip_path)\n",
    "        \n",
    "        if heightmap is None:\n",
    "            raise Exception(\"Failed to extract heightmap\")\n",
    "        \n",
    "        print(f\"  ✓ Heightmap: {heightmap.shape[0]}x{heightmap.shape[1]} pixels\")\n",
    "        \n",
    "        # Extract config files\n",
    "        print(f\"  Extracting config files...\")\n",
    "        init_con, terrain_con = extract_config_files(zip_path)\n",
    "        \n",
    "        # Parse config values\n",
    "        map_size = None\n",
    "        height_scale = None\n",
    "        \n",
    "        if init_con:\n",
    "            map_size = parse_init_con(init_con)\n",
    "        \n",
    "        if terrain_con:\n",
    "            height_scale = parse_terrain_con(terrain_con)\n",
    "        \n",
    "        # Use defaults if not found\n",
    "        if map_size is None:\n",
    "            map_size = 2048 if heightmap.shape[0] == 1025 else 4096\n",
    "            print(f\"  ⚠ Map size not found, using default: {map_size}m\")\n",
    "        else:\n",
    "            print(f\"  ✓ Map size: {map_size}m\")\n",
    "        \n",
    "        if height_scale is None:\n",
    "            height_scale = 300\n",
    "            print(f\"  ⚠ Height scale not found, using default: {height_scale}m\")\n",
    "        else:\n",
    "            print(f\"  ✓ Height scale: {height_scale}m\")\n",
    "        \n",
    "        # Convert to JSON\n",
    "        print(f\"  Converting to JSON...\")\n",
    "        heightmap_json_path = map_output_dir / 'heightmap.json'\n",
    "        \n",
    "        if not convert_heightmap_to_json(heightmap, heightmap_json_path):\n",
    "            raise Exception(\"Failed to convert heightmap to JSON\")\n",
    "        \n",
    "        file_size_mb = heightmap_json_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  ✓ Heightmap JSON: {file_size_mb:.1f} MB\")\n",
    "        \n",
    "        # Generate metadata\n",
    "        print(f\"  Generating metadata...\")\n",
    "        metadata_path = map_output_dir / 'metadata.json'\n",
    "        \n",
    "        if not generate_metadata(map_name, heightmap, map_size, height_scale, metadata_path):\n",
    "            raise Exception(\"Failed to generate metadata\")\n",
    "        \n",
    "        print(f\"  ✓ Metadata JSON created\")\n",
    "        \n",
    "        stats['processed'] += 1\n",
    "        print(f\"  ✓ {map_name} processed successfully\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        stats['errors'] += 1\n",
    "        stats['error_maps'].append(map_name)\n",
    "        print(f\"  ✗ ERROR: {e}\\n\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "duration = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Processing complete!\")\n",
    "print(f\"  Processed: {stats['processed']}/{stats['total']}\")\n",
    "print(f\"  Errors: {stats['errors']}\")\n",
    "print(f\"  Duration: {duration:.1f} seconds ({duration/60:.1f} minutes)\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "if stats['error_maps']:\n",
    "    print(\"Maps with errors:\")\n",
    "    for map_name in stats['error_maps']:\n",
    "        print(f\"  - {map_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad626de0",
   "metadata": {},
   "source": [
    "## Cell 6: Git Commit and Push\n",
    "\n",
    "Automatically commits processed maps and pushes to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if stats['processed'] == 0:\n",
    "    print(\"⚠ No maps processed, skipping git commit\")\n",
    "else:\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Git Commit and Push\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Pull latest changes first\n",
    "        print(\"Pulling latest changes...\")\n",
    "        result = subprocess.run(\n",
    "            ['git', 'pull', 'origin', 'main'],\n",
    "            capture_output=True, text=True, cwd=repo_root\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ Pulled latest changes\")\n",
    "        else:\n",
    "            print(f\"⚠ Pull warning: {result.stderr}\")\n",
    "        \n",
    "        # Stage processed_maps directory\n",
    "        print(\"\\nStaging files...\")\n",
    "        subprocess.run(\n",
    "            ['git', 'add', 'processed_maps/'],\n",
    "            check=True, capture_output=True, cwd=repo_root\n",
    "        )\n",
    "        print(\"✓ Staged processed_maps/\")\n",
    "        \n",
    "        # Check if there are changes to commit\n",
    "        result = subprocess.run(\n",
    "            ['git', 'diff', '--cached', '--name-only'],\n",
    "            capture_output=True, text=True, cwd=repo_root\n",
    "        )\n",
    "        \n",
    "        changed_files = result.stdout.strip().split('\\n')\n",
    "        num_changed = len([f for f in changed_files if f])\n",
    "        \n",
    "        if num_changed == 0:\n",
    "            print(\"\\n⚠ No changes to commit (maps already up to date)\")\n",
    "        else:\n",
    "            print(f\"\\nChanged files: {num_changed}\")\n",
    "            \n",
    "            # Create commit\n",
    "            commit_date = datetime.now().strftime('%Y-%m-%d')\n",
    "            commit_msg = f\"chore: process maps - {stats['processed']} updated ({commit_date})\"\n",
    "            \n",
    "            print(f\"\\nCommitting with message: '{commit_msg}'\")\n",
    "            subprocess.run(\n",
    "                ['git', 'commit', '-m', commit_msg],\n",
    "                check=True, capture_output=True, cwd=repo_root\n",
    "            )\n",
    "            print(\"✓ Committed changes\")\n",
    "            \n",
    "            # Get repository URL and configure with token\n",
    "            result = subprocess.run(\n",
    "                ['git', 'config', '--get', 'remote.origin.url'],\n",
    "                capture_output=True, text=True, check=True, cwd=repo_root\n",
    "            )\n",
    "            repo_url = result.stdout.strip()\n",
    "            \n",
    "            # Convert to HTTPS URL with token if needed\n",
    "            if repo_url.startswith('https://'):\n",
    "                # Remove https://\n",
    "                repo_url = repo_url.replace('https://', '')\n",
    "                # Add token\n",
    "                auth_url = f'https://{GITHUB_TOKEN}@{repo_url}'\n",
    "            elif repo_url.startswith('git@'):\n",
    "                # Convert SSH to HTTPS\n",
    "                repo_url = repo_url.replace('git@github.com:', 'github.com/')\n",
    "                repo_url = repo_url.replace('.git', '')\n",
    "                auth_url = f'https://{GITHUB_TOKEN}@{repo_url}.git'\n",
    "            else:\n",
    "                auth_url = repo_url\n",
    "            \n",
    "            # Push to GitHub\n",
    "            print(\"\\nPushing to GitHub...\")\n",
    "            result = subprocess.run(\n",
    "                ['git', 'push', auth_url, 'main'],\n",
    "                capture_output=True, text=True, cwd=repo_root\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(\"✓ Successfully pushed to GitHub!\")\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(\"✓ All done! Maps are now available in your repository.\")\n",
    "                print(f\"{'='*70}\")\n",
    "            else:\n",
    "                print(f\"\\n✗ Push failed: {result.stderr}\")\n",
    "                print(\"\\nYou may need to manually push changes:\")\n",
    "                print(\"  git push origin main\")\n",
    "    \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n✗ Git operation failed: {e}\")\n",
    "        print(f\"\\nError output: {e.stderr if hasattr(e, 'stderr') else 'N/A'}\")\n",
    "        print(\"\\nYou can manually commit and push:\")\n",
    "        print(\"  git add processed_maps/\")\n",
    "        print(f\"  git commit -m 'chore: process maps - {stats['processed']} updated'\")\n",
    "        print(\"  git push origin main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2942c",
   "metadata": {},
   "source": [
    "## Cell 7: Summary\n",
    "\n",
    "Processing complete! Review the summary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"PROCESSING SUMMARY\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(f\"Maps processed: {stats['processed']}/{stats['total']}\")\n",
    "print(f\"Errors: {stats['errors']}\")\n",
    "\n",
    "if stats['error_maps']:\n",
    "    print(f\"\\nMaps with errors:\")\n",
    "    for map_name in stats['error_maps']:\n",
    "        print(f\"  - {map_name}\")\n",
    "\n",
    "# Calculate total size\n",
    "total_size = 0\n",
    "for map_dir in processed_dir.iterdir():\n",
    "    if map_dir.is_dir():\n",
    "        for file in map_dir.iterdir():\n",
    "            if file.is_file():\n",
    "                total_size += file.stat().st_size\n",
    "\n",
    "total_size_mb = total_size / (1024 * 1024)\n",
    "print(f\"\\nTotal output size: {total_size_mb:.1f} MB\")\n",
    "print(f\"Output directory: {processed_dir}\")\n",
    "\n",
    "# Get repository URL\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['git', 'config', '--get', 'remote.origin.url'],\n",
    "        capture_output=True, text=True, cwd=repo_root\n",
    "    )\n",
    "    repo_url = result.stdout.strip()\n",
    "    \n",
    "    # Convert to web URL\n",
    "    if repo_url.startswith('git@'):\n",
    "        web_url = repo_url.replace('git@github.com:', 'https://github.com/').replace('.git', '')\n",
    "    elif repo_url.startswith('https://'):\n",
    "        web_url = repo_url.replace('.git', '')\n",
    "    else:\n",
    "        web_url = repo_url\n",
    "    \n",
    "    print(f\"\\nRepository: {web_url}\")\n",
    "    print(f\"Processed maps: {web_url}/tree/main/processed_maps\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"NEXT STEPS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "if stats['processed'] > 0:\n",
    "    print(\"1. ✓ Maps processed successfully\")\n",
    "    print(\"2. ✓ Changes committed and pushed to GitHub\")\n",
    "    print(\"3. → Test the calculator: run calculator/server.py\")\n",
    "    print(\"4. → Verify maps load correctly in the web interface\")\n",
    "else:\n",
    "    print(\"⚠ No maps were processed.\")\n",
    "    print(\"  Check errors above and verify raw_map_data/ contains server.zip files.\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ Notebook execution complete!\")\n",
    "print(f\"{'='*70}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
